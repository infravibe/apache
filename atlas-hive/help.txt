https://github.com/apache/hive/blob/master/packaging/src/docker/README.md


Hadoop

NameNode UI: http://13.126.6.218:9870
ResourceManager UI: http://13.126.6.218:8088
NodeManager1 UI: http://13.126.6.218:8042
NodeManager2 UI: http://13.126.6.218:8043
DataNode1 UI: http://13.126.6.218:9864
DataNode2 UI: http://13.126.6.218:9865
History Server UI: http://13.126.6.218:19888


Hive
Postgres: http://13.126.6.218:5432
Metastore: http://13.126.6.218:9083
Hiveserver2: http://13.126.6.218:10000
Hiveserver2 UI: http://13.126.6.218:10002



docker compose -f docker-compose.atlas.yml -f docker-compose.atlas-hadoop.yml -f docker-compose.atlas-hbase.yml -f docker-compose.atlas-kafka.yml -f docker-compose.atlas-hive.yml up -d

docker compose -f docker-compose.atlas.yml -f docker-compose.atlas-hadoop.yml -f docker-compose.atlas-hbase.yml -f docker-compose.atlas-kafka.yml -f docker-compose.atlas-hive.yml down -v



# Hbase
hdfs dfs -mkdir /hbase
hdfs dfs -chown hbase:hbase /hbase

hdfs dfs -ls /

# Create Hive warehouse directory
hdfs dfs -mkdir -p /user/hive/warehouse
hdfs dfs -chmod 1777 /user/hive/warehouse
hdfs dfs -chown -R hive:hive /user/hive/warehouse

# Create Hive scratch directory
hdfs dfs -mkdir -p /hive/tmp
hdfs dfs -chmod 1777 /hive/tmp
hdfs dfs -chown -R hive:hive /hive/tmp

# Create Hive install directory
hdfs dfs -mkdir -p /user/hive/install
hdfs dfs -chmod 755 /user/hive/install
hdfs dfs -chown -R hive:hive /user/hive/install

hdfs dfs -ls -d /user/hive/warehouse
hdfs dfs -ls -d /hive/tmp
hdfs dfs -ls -d /user/hive/install




docker exec -it namenode /bin/sh


beeline -u jdbc:hive2://localhost:10000

CREATE TABLE test_table (
  id INT,
  name STRING
)
STORED AS TEXTFILE;

INSERT INTO test_table VALUES (1, 'Alice'), (2, 'Bob');


SELECT * FROM test_table;

